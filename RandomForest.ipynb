{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# pull feature engineering notebook\n",
    "# add your own feature engineering functions to features.py and import them\n",
    "# only rule is the function must take a dataframe and return a dataframe (with your new features)\n",
    "from features import *\n",
    "\n",
    "color = sns.color_palette()\n",
    "%matplotlib inline\n",
    "\n",
    "df_train = pd.read_json(\"train.json\")\n",
    "df_test = pd.read_json(\"test.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRE-PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#engineer features (from script)\n",
    "scrub_and_engineer = [scrub, engineer, n_log_price, n_expensive]\n",
    "for func in scrub_and_engineer:\n",
    "    try:\n",
    "        df_train = func(df_train)\n",
    "        df_test = func(df_test)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exclude = ['price']\n",
    "feats_to_train = [x for x in df_train.columns.tolist() if df_train[x].dtype not in ['O', '<M8[ns]'] and x not in exclude]\n",
    "feats_to_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cross val\n",
    "test_size=0.20\n",
    "\n",
    "# Random Forest\n",
    "n_estimators=1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feats_to_train = [\"bathrooms\", \"bedrooms\", \"latitude\", \"longitude\", \"price\",\n",
    "             \"num_photos\", \"num_features\", \"num_description_words\",\n",
    "             \"created_year\", \"created_month\", \"created_day\"]\n",
    "X = df_train[feats_to_train]\n",
    "y = df_train[\"interest_level\"]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=test_size)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=n_estimators)\n",
    "clf.fit(X_train, y_train)\n",
    "y_val_pred = clf.predict_proba(X_val)\n",
    "baseline_logloss = log_loss(y_val, y_val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "baseline_logloss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# feats_to_train = [\"bathrooms\", \"bedrooms\", \"latitude\", \"longitude\", \"price\",\n",
    "#              \"num_photos\", \"num_features\", \"num_description_words\",\n",
    "#              \"created_year\", \"created_month\", \"created_day\", 'n_num_keyfeat_score', 'n_no_photo']\n",
    "\n",
    "# filter out any object/string + timestamp variables and train the random forest on numerical columns\n",
    "# feats_to_train = [x for x in df_train.columns.tolist() if df_train[x].dtype not in ['O', '<M8[ns]']] \n",
    "X = df_train[feats_to_train]\n",
    "y = df_train[\"interest_level\"]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=test_size)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=n_estimators)\n",
    "clf.fit(X_train, y_train)\n",
    "y_val_pred = clf.predict_proba(X_val)\n",
    "test_logloss = log_loss(y_val, y_val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_logloss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "dtrain = xgb.DMatrix('demo/data/agaricus.txt.train')\n",
    "dtest = xgb.DMatrix('demo/data/agaricus.txt.test')\n",
    "# specify parameters via map\n",
    "param = {\n",
    "        'max_depth':2, \n",
    "        'eta':1, \n",
    "        'silent':0, #prints running messages while training \n",
    "        'objective':'binary:logistic',\n",
    "        'booster':'gbtree', #options: gbtree, gblinear or dart\n",
    "        'early_stopping_rounds':10\n",
    "        }\n",
    "num_round = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bst = xgb.train(param, dtrain, num_round)\n",
    "preds = bst.predict(dtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Testing for raw improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if baseline_logloss - test_logloss > 0:\n",
    "    print \"Model improved, save and submit\"\n",
    "else:\n",
    "    print \"Use baseline model, did not improve\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up and output a submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def output(df_test, clf):\n",
    "    X = df_test[feats_to_train]\n",
    "    y = clf.predict_proba(X)\n",
    "    labels2idx = {label: i for i, label in enumerate(clf.classes_)}\n",
    "    sub = pd.DataFrame()\n",
    "    sub[\"listing_id\"] = df_test[\"listing_id\"]\n",
    "    for label in [\"high\", \"medium\", \"low\"]:\n",
    "        sub[label] = y[:, labels2idx[label]]\n",
    "    return sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub = output(df_test, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub.to_csv(\"submission_rf.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv('submission_rf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(submission)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### DRACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "lbl = preprocessing.LabelEncoder()\n",
    "\n",
    "#list of id's to encode\n",
    "manager_ids = list(df_train['manager_id'].values)\n",
    "#new var to create\n",
    "new_var = 'manager_id'#'manager_id_encoded'\n",
    "#response var\n",
    "resp_var = 'interest_level'\n",
    "\n",
    "#encode\n",
    "# lbl.fit(manager_ids)\n",
    "# df_train[new_var] = lbl.transform(manager_ids)\n",
    "\n",
    "temp = pd.concat([df_train[new_var], pd.get_dummies(df_train[resp_var])], axis = 1).groupby(new_var).mean()\n",
    "temp.columns = ['high_frac','low_frac', 'medium_frac']\n",
    "temp['count'] = df_train.groupby(new_var).count().iloc[:,1]\n",
    "\n",
    "# compute skill\n",
    "temp['manager_skill'] = temp['high_frac']*2 + temp['medium_frac']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unranked_managers_ixes = temp['count']<20\n",
    "ranked_managers_ixes = ~unranked_managers_ixes\n",
    "mean_values = temp.loc[ranked_managers_ixes, ['high_frac','low_frac', 'medium_frac','manager_skill']].mean()\n",
    "temp.loc[unranked_managers_ixes,['high_frac','low_frac', 'medium_frac','manager_skill']] = mean_values.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lbl = preprocessing.LabelEncoder()\n",
    "lbl.fit(list(df_train['manager_id'].values))\n",
    "df_train['manager_id'] = lbl.transform(list(df_train['manager_id'].values))\n",
    "\n",
    "features_to_use = [\"latitude\", \n",
    "                   \"longitude\", \n",
    "                   \"price\", \n",
    "                   \"num_photos\", \n",
    "                   \"num_features\", \n",
    "                   \"num_description_words\",\n",
    "                   \"manager_id_encoded\"\n",
    "                   ]\n",
    "\n",
    "# X = df_train[features_to_use]\n",
    "# y = df_train[\"interest_level\"]\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "# compute fractions and count for each manager\n",
    "temp = pd.concat([X_train.manager_id,pd.get_dummies(y_train)], axis = 1).groupby('manager_id').mean()\n",
    "temp.columns = ['high_frac','low_frac', 'medium_frac']\n",
    "temp['count'] = X_train.groupby('manager_id').count().iloc[:,1]\n",
    "\n",
    "# compute skill\n",
    "temp['manager_skill'] = temp['high_frac']*2 + temp['medium_frac']\n",
    "\n",
    "# get ixes for unranked managers...\n",
    "unranked_managers_ixes = temp['count']<20\n",
    "# ... and ranked ones\n",
    "ranked_managers_ixes = ~unranked_managers_ixes\n",
    "\n",
    "# compute mean values from ranked managers and assign them to unranked ones\n",
    "mean_values = temp.loc[ranked_managers_ixes, ['high_frac','low_frac', 'medium_frac','manager_skill']].mean()\n",
    "print(mean_values)\n",
    "temp.loc[unranked_managers_ixes,['high_frac','low_frac', 'medium_frac','manager_skill']] = mean_values.values"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py27]",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
