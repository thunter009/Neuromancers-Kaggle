{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data and New Variable Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Info\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(49352, 15)\n",
      "Index([u'bathrooms', u'bedrooms', u'building_id', u'created', u'description',\n",
      "       u'display_address', u'features', u'interest_level', u'latitude',\n",
      "       u'listing_id', u'longitude', u'manager_id', u'photos', u'price',\n",
      "       u'street_address'],\n",
      "      dtype='object')\n",
      "-----------------------------------------------------------------\n",
      "Test Set Info\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(74659, 14)\n",
      "Index([u'bathrooms', u'bedrooms', u'building_id', u'created', u'description',\n",
      "       u'display_address', u'features', u'latitude', u'listing_id',\n",
      "       u'longitude', u'manager_id', u'photos', u'price', u'street_address'],\n",
      "      dtype='object')\n",
      "-----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "color = sns.color_palette()\n",
    "%matplotlib inline\n",
    "\n",
    "t_df = pd.read_json(\"train.json\") # training set\n",
    "ts_df = pd.read_json(\"test.json\") # test set\n",
    "\n",
    "print 'Training Set Info'\n",
    "print(type(t_df))\n",
    "print(t_df.shape) # 49,352 obs and 15 vars\n",
    "print(t_df.columns)\n",
    "print 65*'-'\n",
    "print 'Test Set Info'\n",
    "print(type(ts_df))\n",
    "print(ts_df.shape) # 74,659 obs and 14 vars (reponse var: interest_level not provided as expected)\n",
    "print(ts_df.columns)\n",
    "print 65*'-'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tube_lat_long = pd.read_csv('http://web.mta.info/developers/data/nyct/subway/StationEntrances.csv') \\\n",
    "    [['Station_Name','Station_Latitude','Station_Longitude']]    \n",
    "\n",
    "tube_lat_long = tube_lat_long.groupby('Station_Name').agg(['mean']) # unique stations only\n",
    "    \n",
    "stations=[]\n",
    "for i in range(0,len(tube_lat_long),1):\n",
    "        stations.append(\n",
    "            (tube_lat_long.iloc[:,0][i],tube_lat_long.iloc[:,1][i]))\n",
    "    \n",
    "from geopy.distance import vincenty\n",
    "import numpy as np\n",
    "distance = []\n",
    "for i in range(0,len(t_df['latitude']),1):\n",
    "    lat_long = (list(t_df['latitude'])[i],list(t_df['longitude'])[i])\n",
    "    temp=[]\n",
    "    for j in stations:\n",
    "        temp.append(\n",
    "        vincenty(lat_long, j).meters)\n",
    "    distance.append(max(temp))\n",
    "\n",
    "t_df['dist_to_nearest_tube']= distance    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Creating New Location variables: \n",
    "\n",
    "# new var: n_broadway\n",
    "# training set:\n",
    "import re\n",
    "match_list = map(lambda x: re.search('broadway|b?way|b?wy',x.lower()), list(t_df['display_address']))\n",
    "\n",
    "type_address=[]\n",
    "for i in match_list:\n",
    "    if i== None:\n",
    "        type_address.append(0)\n",
    "    elif i.group()== 'broadway' or i.group()== 'brwy' or i.group()== 'brway': #second filter\n",
    "        type_address.append(1)\n",
    "    else:\n",
    "        type_address.append(0) \n",
    "\n",
    "t_df['n_broadway']= type_address # new variable starts by n_\n",
    "\n",
    "# test set:\n",
    "match_list = map(lambda x: re.search('broadway|b?way|b?wy',x.lower()), list(ts_df['display_address']))\n",
    "\n",
    "type_address=[]\n",
    "for i in match_list:\n",
    "    if i== None:\n",
    "        type_address.append(0)\n",
    "    elif i.group()== 'broadway' or i.group()== 'brwy' or i.group()== 'brway': #second filter\n",
    "        type_address.append(1)\n",
    "    else:\n",
    "        type_address.append(0) \n",
    "\n",
    "ts_df['n_broadway']= type_address # new variable starts by n_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Creating new variables: n_num_keyfeat_score\n",
    "\n",
    "# Training data:\n",
    "match_list=[map(lambda x: re.search('elevator|cats|dogs|doorman|dishwasher|no fee|laundry|fitness',x.lower()),\n",
    "                     list(t_df['features'])[i]) for i in np.arange(0,len(t_df['features']),1)]\n",
    "nfeat_list =[] \n",
    "for i in match_list:\n",
    "    if i==None:\n",
    "        nfeat_list.append(0)\n",
    "    else:\n",
    "        if any(i)== False: # check to filter out lists with no all None values\n",
    "            nfeat_list.append(0)\n",
    "        else:\n",
    "            lis1=[]\n",
    "            map(lambda x: lis1.append(1) if x!= None else lis1.append(0),i)            \n",
    "            nfeat_list.append(sum(lis1))\n",
    "\n",
    "# new variable n_num_keyfeat_score \n",
    "nfeat_score=[]\n",
    "for i in nfeat_list:\n",
    "    if i<=5:\n",
    "        nfeat_score.append(0)\n",
    "    elif i==6:\n",
    "        nfeat_score.append(1)\n",
    "    elif i==7:\n",
    "        nfeat_score.append(2)\n",
    "    elif i==8:\n",
    "        nfeat_score.append(3)\n",
    "    elif i==9:\n",
    "        nfeat_score.append(4)\n",
    "    elif i==10:\n",
    "        nfeat_score.append(5)\n",
    "    else:\n",
    "        nfeat_score.append(6)\n",
    "\n",
    "t_df['n_num_keyfeat_score']= nfeat_score\n",
    "\n",
    "# Test data:\n",
    "match_list=[map(lambda x: re.search('elevator|cats|dogs|doorman|dishwasher|no fee|laundry|fitness',x.lower()),\n",
    "                     list(ts_df['features'])[i]) for i in np.arange(0,len(ts_df['features']),1)]\n",
    "nfeat_list =[] \n",
    "for i in match_list:\n",
    "    if i==None:\n",
    "        nfeat_list.append(0)\n",
    "    else:\n",
    "        if any(i)== False: # check to filter out lists with no all None values\n",
    "            nfeat_list.append(0)\n",
    "        else:\n",
    "            lis1=[]\n",
    "            map(lambda x: lis1.append(1) if x!= None else lis1.append(0),i)            \n",
    "            nfeat_list.append(sum(lis1))\n",
    "\n",
    "nfeat_score=[]\n",
    "for i in nfeat_list:\n",
    "    if i<=5:\n",
    "        nfeat_score.append(0)\n",
    "    elif i==6:\n",
    "        nfeat_score.append(1)\n",
    "    elif i==7:\n",
    "        nfeat_score.append(2)\n",
    "    elif i==8:\n",
    "        nfeat_score.append(3)\n",
    "    elif i==9:\n",
    "        nfeat_score.append(4)\n",
    "    elif i==10:\n",
    "        nfeat_score.append(5)\n",
    "    else:\n",
    "        nfeat_score.append(6)\n",
    "\n",
    "ts_df['n_num_keyfeat_score']= nfeat_score\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# photos related:\n",
    "\n",
    "# new_var: num_photos\n",
    "# training \n",
    "t_df[\"num_photos\"] = t_df[\"photos\"].apply(len)\n",
    "# test \n",
    "ts_df[\"num_photos\"] = ts_df[\"photos\"].apply(len)\n",
    "\n",
    "# new variable: n_no_photo\n",
    "# training set:\n",
    "t_df['n_no_photo'] = [1 if i == 0 else 0 for i in map(len,t_df['photos'])]\n",
    "# training set:\n",
    "ts_df['n_no_photo'] = [1 if i == 0 else 0 for i in map(len,ts_df['photos'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# New Vars related to Price:\n",
    "# new var: square root price\n",
    "# training set\n",
    "t_df['n_price_sqrt'] = t_df['price']**(0.5)\n",
    "# testing set\n",
    "ts_df['n_price_sqrt'] = ts_df['price']**(0.5)\n",
    "\n",
    "# new var: log price\n",
    "# training set\n",
    "t_df['n_log_price'] = np.log(t_df['price'])\n",
    "# testing set\n",
    "ts_df['n_log_price'] = np.log(ts_df['price'])\n",
    "\n",
    "# new var: expensive\n",
    "# training set\n",
    "threshold_75p = t_df[['price']].describe().loc['75%','price']\n",
    "t_df['n_expensive']=[1 if i > threshold_75p else 0 for i in list(t_df['price']) ]\n",
    "# test set\n",
    "threshold_75p = ts_df[['price']].describe().loc['75%','price']\n",
    "ts_df['n_expensive']=[1 if i > threshold_75p else 0 for i in list(ts_df['price'])]\n",
    "\n",
    "# new var: k-neighbours using k=30 price vs median\n",
    "# train:\n",
    "temp = pd.read_json(\"price_vs_median30.json\")['price_vs_median_30']\n",
    "mean = np.mean(temp) \n",
    "import math\n",
    "t_df['price_vs_median_30'] = [mean if math.isnan(i)== True  else round(i,2) for i in temp]\n",
    "\n",
    "# only train done\n",
    "\n",
    "# new var: k-neighbours using k=72 price vs median\n",
    "# train:\n",
    "temp = pd.read_json(\"price_vs_median72.json\")['price_vs_median_72']\n",
    "mean = np.mean(temp) \n",
    "import math\n",
    "t_df['price_vs_median_72'] = [mean if math.isnan(i)== True  else round(i,2) for i in temp]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Carlo\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:27: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "C:\\Users\\Carlo\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:31: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n"
     ]
    }
   ],
   "source": [
    "# new variables: extracted from features.py:\n",
    "\n",
    "# new vars about time:\n",
    "\n",
    "from pandas import to_datetime\n",
    "\n",
    "# training;\n",
    "t_df[\"created\"] = to_datetime(t_df[\"created\"])\n",
    "t_df[\"created_year\"] = t_df[\"created\"].dt.year\n",
    "t_df[\"created_month\"] = t_df[\"created\"].dt.month\n",
    "t_df[\"created_day\"] = t_df[\"created\"].dt.day\n",
    "# test:\n",
    "ts_df[\"created\"] = to_datetime(ts_df[\"created\"])\n",
    "ts_df[\"created_year\"] = ts_df[\"created\"].dt.year\n",
    "ts_df[\"created_month\"] = ts_df[\"created\"].dt.month\n",
    "ts_df[\"created_day\"] = ts_df[\"created\"].dt.day\n",
    "\n",
    "# new var: num_description_words:\n",
    "# training set\n",
    "t_df[\"num_description_words\"] = t_df[\"description\"].apply(lambda x: len(x.split(\" \")))\n",
    "# test set\n",
    "ts_df[\"num_description_words\"] = ts_df[\"description\"].apply(lambda x: len(x.split(\" \")))\n",
    "\n",
    "# new var: has_phone:\n",
    "# training set:\n",
    "phone_regex = \"(\\d{3}[-\\.\\s]??\\d{3}[-\\.\\s]??\\d{4}|\\(\\d{3}\\)\\s*\\d{3}[-\\.\\s]??\\d{4}|\\d{3}[-\\.\\s]??\\d{4})\" # http://stackoverflow.com/questions/16699007/regular-expression-to-match-standard-10-digit-phone-number\n",
    "has_phone = t_df['description'].str.extract(phone_regex)\n",
    "t_df['has_phone']=[type(item)==unicode for item in has_phone]\n",
    "# test set\n",
    "phone_regex = \"(\\d{3}[-\\.\\s]??\\d{3}[-\\.\\s]??\\d{4}|\\(\\d{3}\\)\\s*\\d{3}[-\\.\\s]??\\d{4}|\\d{3}[-\\.\\s]??\\d{4})\" # http://stackoverflow.com/questions/16699007/regular-expression-to-match-standard-10-digit-phone-number\n",
    "has_phone = ts_df['description'].str.extract(phone_regex)\n",
    "ts_df['has_phone']=[type(item)==unicode for item in has_phone]\n",
    "\n",
    "\n",
    "# new var: distance_from_midtown\n",
    "\n",
    "# https://github.com/geopy/geopy\n",
    "# calculates vincenty dist\n",
    "# https://en.wikipedia.org/wiki/Vincenty's_formulae\n",
    "\n",
    "from geopy.distance import vincenty\n",
    "lat = t_df['latitude'].tolist()\n",
    "long_ = t_df['longitude'].tolist()\n",
    "midtown_lat = 40.7586\n",
    "midtown_long = -73.9838\n",
    "distance = []\n",
    "for i in range(len(lat)):\n",
    "    distance.append(\n",
    "        vincenty((lat[i], long_[i]), (midtown_lat, midtown_long)).meters)\n",
    "t_df['distance_from_midtown'] = distance\n",
    "\n",
    "# test:\n",
    "from geopy.distance import vincenty\n",
    "lat = ts_df['latitude'].tolist()\n",
    "long_ = ts_df['longitude'].tolist()\n",
    "midtown_lat = 40.7586\n",
    "midtown_long = -73.9838\n",
    "distance = []\n",
    "for i in range(len(lat)):\n",
    "    distance.append(\n",
    "        vincenty((lat[i], long_[i]), (midtown_lat, midtown_long)).meters)\n",
    "ts_df['distance_from_midtown'] = distance\n",
    "\n",
    "\n",
    "# new var: dist_to_nearest_college\n",
    "\n",
    "Baruch = (40.7402, -73.9834)\n",
    "Columbia = (40.8075, -73.9626)\n",
    "Cooper_Union = (40.7299, -73.9903)\n",
    "FIT = (40.7475, -73.9951)\n",
    "Hunter_College = (40.7685, -73.9657)\n",
    "John_Jay = (40.7704, -73.9885)\n",
    "Julliard = (40.7738, -73.9828)\n",
    "NYU = (40.7295, -73.9965)\n",
    "NYU_Tandon = (40.6942, -73.9866)\n",
    "Pace_University=(40.7111, -74.0049)\n",
    "Pratt_University = (40.6913, -73.9625)\n",
    "The_New_School = (40.7355199, -73.99715879999997)\n",
    "Weill_Cornell = (40.7650, -73.9548) \n",
    "\n",
    "schools = [Baruch,Columbia,Cooper_Union,FIT,Hunter_College,John_Jay, Julliard, NYU, NYU_Tandon,\n",
    "          Pace_University, Pratt_University, The_New_School, Weill_Cornell]\n",
    "                 \n",
    "from geopy.distance import vincenty\n",
    "import numpy as np\n",
    "# https://github.com/geopy/geopy\n",
    "# calculates vincenty dist\n",
    "# https://en.wikipedia.org/wiki/Vincenty's_formulae\n",
    "\n",
    "distance = []\n",
    "for i in range(0,len(t_df['latitude']),1):\n",
    "    lat_long = (list(t_df['latitude'])[i],list(t_df['longitude'])[i])\n",
    "    temp=[]\n",
    "    for j in schools:\n",
    "        temp.append(\n",
    "        vincenty(lat_long, j).meters)\n",
    "    distance.append(min(temp))\n",
    "\n",
    "t_df['dist_to_nearest_school']= distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# new var: dist_to_nearest_tube\n",
    "tube_lat_long = pd.read_csv('http://web.mta.info/developers/data/nyct/subway/StationEntrances.csv') \\\n",
    "    [['Station_Name','Station_Latitude','Station_Longitude']]    \n",
    "\n",
    "tube_lat_long = tube_lat_long.groupby('Station_Name').agg(['mean']) # unique stations only\n",
    "    \n",
    "stations=[]\n",
    "for i in range(0,len(tube_lat_long),1):\n",
    "        stations.append(\n",
    "            (tube_lat_long.iloc[:,0][i],tube_lat_long.iloc[:,1][i]))\n",
    "    \n",
    "from geopy.distance import vincenty\n",
    "import numpy as np\n",
    "distance = []\n",
    "for i in range(0,len(t_df['latitude']),1):\n",
    "    lat_long = (list(t_df['latitude'])[i],list(t_df['longitude'])[i])\n",
    "    temp=[]\n",
    "    for j in stations:\n",
    "        temp.append(\n",
    "        vincenty(lat_long, j).meters)\n",
    "    distance.append(min(temp))\n",
    "\n",
    "t_df['dist_to_nearest_tube']= distance    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# new var: management_skill\n",
    "\n",
    "#new var to create\n",
    "new_var = 'manager_id'#'manager_id_encoded'\n",
    "#response var\n",
    "resp_var = 'interest_level'\n",
    "temp = pd.concat([t_df[new_var], pd.get_dummies(t_df[resp_var])], axis = 1).groupby(new_var).mean()\n",
    "temp.columns = ['high_frac','low_frac', 'medium_frac']\n",
    "temp['count'] = t_df.groupby(new_var).count().iloc[:,1]\n",
    "temp['manager_skill'] = temp['high_frac']*2 + temp['medium_frac']\n",
    "manager_skill=[]\n",
    "for i in t_df['manager_id']:\n",
    "    for j in temp.index:\n",
    "        if i==j:\n",
    "            manager_skill.append(temp['manager_skill'][j])\n",
    "t_df['manager_skill']=manager_skill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Response and Predictor Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([             u'bathrooms',               u'bedrooms',\n",
       "                  u'building_id',                u'created',\n",
       "                  u'description',        u'display_address',\n",
       "                     u'features',         u'interest_level',\n",
       "                     u'latitude',             u'listing_id',\n",
       "                    u'longitude',             u'manager_id',\n",
       "                       u'photos',                  u'price',\n",
       "               u'street_address',             u'n_broadway',\n",
       "          u'n_num_keyfeat_score',             u'num_photos',\n",
       "                   u'n_no_photo',           u'n_price_sqrt',\n",
       "                  u'n_log_price',            u'n_expensive',\n",
       "           u'price_vs_median_30',     u'price_vs_median_72',\n",
       "                 u'created_year',          u'created_month',\n",
       "                  u'created_day',  u'num_description_words',\n",
       "                    u'has_phone',  u'distance_from_midtown',\n",
       "                u'manager_skill', u'dist_to_nearest_school',\n",
       "         u'dist_to_nearest_tube'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_df.columns # training set cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export new DF to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check first whether you want to export pred_logit or other model parameter list\n",
    "ext = pred_logit + ['interest_level']\n",
    "\n",
    "t_df.loc[:, ext].loc[:, ext].to_csv('new_train.csv', encoding='utf-8')\n",
    "#ts_df.to_csv('new_test.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logit Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logit Model: Select Vars**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Bathrooms and Buildings are significant, yet they have some multicolinearity between them and against log_price\n",
    "- Log Price and n_expensive are very significant, yet some thye exhibit some multicolinearity (as expected)\n",
    "- New var 'distance_from_midtown' not relevant for Logit. Latitude-Longitude are more useful.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# predictor list with variables whom relevance has been tested:\n",
    "pred_logit = ['bathrooms', 'bedrooms', 'n_broadway','price_vs_median_30', 'n_log_price','n_expensive',\n",
    "              'n_no_photo','num_photos', 'n_num_keyfeat_score', 'num_description_words', 'has_phone',\n",
    "              'manager_skill','dist_to_nearest_tube']\n",
    "## separate the predictors and response in the training data set\n",
    "x = np.array(t_df.loc[:, pred_logit])\n",
    "y = np.ravel(t_df.loc[:, 'interest_level'])\n",
    "## separate the predictors and response in the test data set\n",
    "x2 = np.array(ts_df.loc[:, pred_logit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictor Parameters are: {'warm_start': False, 'C': 10000.0, 'n_jobs': 1, 'verbose': 0, 'intercept_scaling': 1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'multi_class': 'ovr', 'random_state': None, 'dual': False, 'tol': 0.0001, 'solver': 'liblinear', 'class_weight': None}\n",
      "-----------------------------------------------------------------\n",
      "Predictor Coefficients are: [[ -1.69698985e-01   1.17511776e-01   3.56829847e-02  -1.24547828e+00\n",
      "   -3.87571020e-01  -3.88119024e-01  -3.82027456e-01  -1.71238048e-02\n",
      "    5.49471635e-02  -5.94429477e-04   7.82780248e-02   3.24191039e+00\n",
      "   -2.42040840e-04]\n",
      " [  7.55544360e-01  -1.32714383e-01  -8.45612902e-02   2.01871099e+00\n",
      "    3.26915976e-02  -2.06006721e-01   1.28212614e+00   1.89413677e-02\n",
      "   -1.47549506e-01  -4.06040852e-04  -7.96152599e-02  -3.51427768e+00\n",
      "    1.44660825e-07]\n",
      " [ -2.63583947e-01   2.34899689e-01   1.06032418e-02  -6.57854984e-01\n",
      "   -2.01606455e-01  -3.65619120e-01  -4.95734454e-01  -5.29038573e-03\n",
      "    1.48886469e-01   7.14506177e-04   2.86491640e-01   1.72680255e+00\n",
      "   -1.05084306e-07]]\n",
      "Intercept [ 0.2434921  -0.55702202  0.08357357]\n"
     ]
    }
   ],
   "source": [
    "### 1. Logit Model\n",
    "from sklearn import linear_model\n",
    "logit_1 = linear_model.LogisticRegression()\n",
    "logit_1\n",
    "\n",
    "logit_1.set_params(C=1e4) # is the inverse of regularization strength. \n",
    "# This is opposite to the alphaused in Ridge and Lasso. Smaller values specify stronger regularization.\n",
    "logit_1.fit(x, y)\n",
    "print 'Predictor Parameters are:',logit_1.get_params() \n",
    "print 65*'-'\n",
    "print 'Predictor Coefficients are:',logit_1.coef_\n",
    "print 'Intercept',logit_1.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.732999675798\n",
      "Misc.Error on training set: 0.267000324202\n"
     ]
    }
   ],
   "source": [
    "# 2) Accuracy on  Training Set\n",
    "print 'Accuracy on training set:', logit_1.score(x,y) \n",
    "print 'Misc.Error on training set:', 1- logit_1.score(x,y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi Class Log_loss: 0.606577702673\n"
     ]
    }
   ],
   "source": [
    "# 3) Acid test: prediction and log-loss indicator\n",
    "# http://stackoverflow.com/questions/35013822/log-loss-output-is-greater-than-1\n",
    "# log-loss range is [0,inf] => the close to 0, the better\n",
    "from sklearn import metrics \n",
    "y_pred = logit_1.predict(x)\n",
    "y_pred_p = logit_1.predict_proba(x)\n",
    "print 'Multi Class Log_loss:', metrics.log_loss(y,y_pred_p) # log_loss(x,y) => x= true label format [], x= predicted probs [[]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average .Accuracy is 0.731089\n",
      "Average Miscl. Error is 0.268911\n",
      "Average StDev Misc.Error is 0.006984\n"
     ]
    }
   ],
   "source": [
    "# 4) Cross-Validation:\n",
    "import sklearn.cross_validation as cv\n",
    "\n",
    "mean_error = []\n",
    "std_error = []\n",
    "kfold = range(3, 15)\n",
    "for i in kfold:\n",
    "    scores = cv.cross_val_score(logit_1, x, y, cv=i)\n",
    "    mean_error.append(1-scores.mean())\n",
    "    std_error.append(scores.std())\n",
    "    \n",
    "\n",
    "print 'Average .Accuracy is %f'%(1-np.mean(mean_error))\n",
    "print 'Average Miscl. Error is %f'%(np.mean(mean_error))\n",
    "print 'Average StDev Misc.Error is %f'%(np.mean(std_error))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x5f23eef0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhEAAAF9CAYAAAC6QDquAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJKQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x4a22940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pylab inline \n",
    "import matplotlib.pyplot as pl\n",
    "s1 = pl.scatter(kfold, mean_error, label='mean error')\n",
    "pl.plot(kfold, mean_error)\n",
    "s2 = pl.scatter(kfold, std_error, color='red', label='std')\n",
    "pl.plot(kfold, std_error, color='red')\n",
    "pl.xlim(0, 15)\n",
    "pl.xlabel('number of fold')\n",
    "pl.legend(handles=[s1, s2], loc=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminant Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discriminant Analysis Models theory:\n",
    "- All models (LDA, QDA, GNB) assume features follow a gaussian distribution. \n",
    "- In other words, these models are heavily impacted by fat tails and skew.\n",
    "- LDA assumes different means per class but equal stand.deviation. \n",
    "- QDA assumes variance and correl between parameters is different.\n",
    "- GNB (Gauss Naive Bayes) goes one step further suggesting variance is different, yet correl between features is nil. \n",
    "\n",
    "Observations about our training sample:\n",
    "- Several important variables, like price, have high kurtosis and above-normal skew levels.\n",
    "- Hence, gaussian asssumption to work out a priori conditional probabilities is a risky one.\n",
    "- Leaving out non-gaussian features is not helpful: price is a very important indicator about interest_level.\n",
    "- Correlation between features within each class is 0.17 on average but can move from -0.015 to 0.33. \n",
    "- Correlation between features within each class is almost the same across classes range. \n",
    "- Price and Price-related vars seem to be the ones with highest correlation with other features.\n",
    "- Bathrooms-Bedrooms-Price variables all have multicolinearity risk\n",
    "\n",
    "Training sample conclusion:\n",
    "- The gaussian asssumption to work out a priori conditional probabilities is a risky one for this dataset.\n",
    "- Overall intra-class feature correlations are low (0.17), yet depeding on the eventual chosen predictors Naive Bayes assumptions (nil correl) could either makes sense or not.\n",
    "- Overall inter-class feature correlation differences are also within a tight range (-3% to +5%).\n",
    "- Price and price-related vars are the one correlating the most with other features. \n",
    "- If we only take into consideration a single price predictor, we find it only correlated strongly with bathrooms and bedrooms (0.67 and 0.58).\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>n_broadway</th>\n",
       "      <th>price_vs_median_30</th>\n",
       "      <th>n_log_price</th>\n",
       "      <th>n_expensive</th>\n",
       "      <th>n_no_photo</th>\n",
       "      <th>num_photos</th>\n",
       "      <th>n_num_keyfeat_score</th>\n",
       "      <th>num_description_words</th>\n",
       "      <th>has_phone</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interest_level</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">high</th>\n",
       "      <th>count</th>\n",
       "      <td>3839.000000</td>\n",
       "      <td>3839.000000</td>\n",
       "      <td>3839.000000</td>\n",
       "      <td>3839.000000</td>\n",
       "      <td>3839.000000</td>\n",
       "      <td>3839.000000</td>\n",
       "      <td>3839.000000</td>\n",
       "      <td>3839.000000</td>\n",
       "      <td>3839.000000</td>\n",
       "      <td>3839.000000</td>\n",
       "      <td>3839.000000</td>\n",
       "      <td>3839.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.116176</td>\n",
       "      <td>1.546496</td>\n",
       "      <td>-73.964613</td>\n",
       "      <td>40.748007</td>\n",
       "      <td>0.014587</td>\n",
       "      <td>0.824595</td>\n",
       "      <td>7.815520</td>\n",
       "      <td>0.107059</td>\n",
       "      <td>0.013024</td>\n",
       "      <td>5.738474</td>\n",
       "      <td>0.457671</td>\n",
       "      <td>91.258140</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.341725</td>\n",
       "      <td>1.112187</td>\n",
       "      <td>0.040286</td>\n",
       "      <td>0.051965</td>\n",
       "      <td>0.119909</td>\n",
       "      <td>0.767489</td>\n",
       "      <td>0.386224</td>\n",
       "      <td>0.309229</td>\n",
       "      <td>0.113393</td>\n",
       "      <td>2.689384</td>\n",
       "      <td>1.045957</td>\n",
       "      <td>54.509445</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-74.159800</td>\n",
       "      <td>40.575800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>6.551080</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-73.990350</td>\n",
       "      <td>40.721900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>7.522941</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-73.976300</td>\n",
       "      <td>40.746500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>7.783224</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-73.948600</td>\n",
       "      <td>40.773800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>8.059276</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>-73.714200</td>\n",
       "      <td>41.086800</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>46.300000</td>\n",
       "      <td>11.618285</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>549.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">low</th>\n",
       "      <th>count</th>\n",
       "      <td>34284.000000</td>\n",
       "      <td>34284.000000</td>\n",
       "      <td>34284.000000</td>\n",
       "      <td>34284.000000</td>\n",
       "      <td>34284.000000</td>\n",
       "      <td>34284.000000</td>\n",
       "      <td>34284.000000</td>\n",
       "      <td>34284.000000</td>\n",
       "      <td>34284.000000</td>\n",
       "      <td>34284.000000</td>\n",
       "      <td>34284.000000</td>\n",
       "      <td>34284.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.238741</td>\n",
       "      <td>1.514759</td>\n",
       "      <td>-73.951667</td>\n",
       "      <td>40.739504</td>\n",
       "      <td>0.010442</td>\n",
       "      <td>1.163428</td>\n",
       "      <td>8.165793</td>\n",
       "      <td>0.287773</td>\n",
       "      <td>0.100397</td>\n",
       "      <td>5.524647</td>\n",
       "      <td>0.445922</td>\n",
       "      <td>87.525201</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.544946</td>\n",
       "      <td>1.111595</td>\n",
       "      <td>1.355388</td>\n",
       "      <td>0.732933</td>\n",
       "      <td>0.101654</td>\n",
       "      <td>8.341650</td>\n",
       "      <td>0.441250</td>\n",
       "      <td>0.452731</td>\n",
       "      <td>0.300533</td>\n",
       "      <td>3.981574</td>\n",
       "      <td>0.960691</td>\n",
       "      <td>60.732700</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-118.271000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>3.761200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-73.991800</td>\n",
       "      <td>40.729700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>7.872836</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-73.977900</td>\n",
       "      <td>40.753800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.040000</td>\n",
       "      <td>8.101678</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-73.956000</td>\n",
       "      <td>40.774725</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.240000</td>\n",
       "      <td>8.389360</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>44.883500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1407.520000</td>\n",
       "      <td>15.317363</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>667.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">medium</th>\n",
       "      <th>count</th>\n",
       "      <td>11229.000000</td>\n",
       "      <td>11229.000000</td>\n",
       "      <td>11229.000000</td>\n",
       "      <td>11229.000000</td>\n",
       "      <td>11229.000000</td>\n",
       "      <td>11229.000000</td>\n",
       "      <td>11229.000000</td>\n",
       "      <td>11229.000000</td>\n",
       "      <td>11229.000000</td>\n",
       "      <td>11229.000000</td>\n",
       "      <td>11229.000000</td>\n",
       "      <td>11229.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.163906</td>\n",
       "      <td>1.622050</td>\n",
       "      <td>-73.965033</td>\n",
       "      <td>40.745567</td>\n",
       "      <td>0.012735</td>\n",
       "      <td>0.930973</td>\n",
       "      <td>7.992128</td>\n",
       "      <td>0.176151</td>\n",
       "      <td>0.010954</td>\n",
       "      <td>5.813251</td>\n",
       "      <td>0.590168</td>\n",
       "      <td>97.733547</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.388318</td>\n",
       "      <td>1.122604</td>\n",
       "      <td>0.698923</td>\n",
       "      <td>0.388466</td>\n",
       "      <td>0.112133</td>\n",
       "      <td>0.226014</td>\n",
       "      <td>0.354204</td>\n",
       "      <td>0.380966</td>\n",
       "      <td>0.104090</td>\n",
       "      <td>2.654043</td>\n",
       "      <td>1.118629</td>\n",
       "      <td>56.112246</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-75.177300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>6.543912</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-73.991800</td>\n",
       "      <td>40.726500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>7.740664</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-73.978100</td>\n",
       "      <td>40.748800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>7.970740</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-73.953300</td>\n",
       "      <td>40.772400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.060000</td>\n",
       "      <td>8.202482</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>44.603800</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.690000</td>\n",
       "      <td>9.615805</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>630.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         bathrooms      bedrooms     longitude      latitude  \\\n",
       "interest_level                                                                 \n",
       "high           count   3839.000000   3839.000000   3839.000000   3839.000000   \n",
       "               mean       1.116176      1.546496    -73.964613     40.748007   \n",
       "               std        0.341725      1.112187      0.040286      0.051965   \n",
       "               min        0.000000      0.000000    -74.159800     40.575800   \n",
       "               25%        1.000000      1.000000    -73.990350     40.721900   \n",
       "               50%        1.000000      2.000000    -73.976300     40.746500   \n",
       "               75%        1.000000      2.000000    -73.948600     40.773800   \n",
       "               max        4.000000      5.000000    -73.714200     41.086800   \n",
       "low            count  34284.000000  34284.000000  34284.000000  34284.000000   \n",
       "               mean       1.238741      1.514759    -73.951667     40.739504   \n",
       "               std        0.544946      1.111595      1.355388      0.732933   \n",
       "               min        0.000000      0.000000   -118.271000      0.000000   \n",
       "               25%        1.000000      1.000000    -73.991800     40.729700   \n",
       "               50%        1.000000      1.000000    -73.977900     40.753800   \n",
       "               75%        1.000000      2.000000    -73.956000     40.774725   \n",
       "               max       10.000000      8.000000      0.000000     44.883500   \n",
       "medium         count  11229.000000  11229.000000  11229.000000  11229.000000   \n",
       "               mean       1.163906      1.622050    -73.965033     40.745567   \n",
       "               std        0.388318      1.122604      0.698923      0.388466   \n",
       "               min        0.000000      0.000000    -75.177300      0.000000   \n",
       "               25%        1.000000      1.000000    -73.991800     40.726500   \n",
       "               50%        1.000000      2.000000    -73.978100     40.748800   \n",
       "               75%        1.000000      2.000000    -73.953300     40.772400   \n",
       "               max        4.000000      7.000000      0.000000     44.603800   \n",
       "\n",
       "                        n_broadway  price_vs_median_30   n_log_price  \\\n",
       "interest_level                                                         \n",
       "high           count   3839.000000         3839.000000   3839.000000   \n",
       "               mean       0.014587            0.824595      7.815520   \n",
       "               std        0.119909            0.767489      0.386224   \n",
       "               min        0.000000            0.090000      6.551080   \n",
       "               25%        0.000000            0.630000      7.522941   \n",
       "               50%        0.000000            0.810000      7.783224   \n",
       "               75%        0.000000            0.960000      8.059276   \n",
       "               max        1.000000           46.300000     11.618285   \n",
       "low            count  34284.000000        34284.000000  34284.000000   \n",
       "               mean       0.010442            1.163428      8.165793   \n",
       "               std        0.101654            8.341650      0.441250   \n",
       "               min        0.000000            0.020000      3.761200   \n",
       "               25%        0.000000            0.880000      7.872836   \n",
       "               50%        0.000000            1.040000      8.101678   \n",
       "               75%        0.000000            1.240000      8.389360   \n",
       "               max        1.000000         1407.520000     15.317363   \n",
       "medium         count  11229.000000        11229.000000  11229.000000   \n",
       "               mean       0.012735            0.930973      7.992128   \n",
       "               std        0.112133            0.226014      0.354204   \n",
       "               min        0.000000            0.140000      6.543912   \n",
       "               25%        0.000000            0.780000      7.740664   \n",
       "               50%        0.000000            0.940000      7.970740   \n",
       "               75%        0.000000            1.060000      8.202482   \n",
       "               max        1.000000            2.690000      9.615805   \n",
       "\n",
       "                       n_expensive    n_no_photo    num_photos  \\\n",
       "interest_level                                                   \n",
       "high           count   3839.000000   3839.000000   3839.000000   \n",
       "               mean       0.107059      0.013024      5.738474   \n",
       "               std        0.309229      0.113393      2.689384   \n",
       "               min        0.000000      0.000000      0.000000   \n",
       "               25%        0.000000      0.000000      4.000000   \n",
       "               50%        0.000000      0.000000      5.000000   \n",
       "               75%        0.000000      0.000000      7.000000   \n",
       "               max        1.000000      1.000000     26.000000   \n",
       "low            count  34284.000000  34284.000000  34284.000000   \n",
       "               mean       0.287773      0.100397      5.524647   \n",
       "               std        0.452731      0.300533      3.981574   \n",
       "               min        0.000000      0.000000      0.000000   \n",
       "               25%        0.000000      0.000000      4.000000   \n",
       "               50%        0.000000      0.000000      5.000000   \n",
       "               75%        1.000000      0.000000      7.000000   \n",
       "               max        1.000000      1.000000     68.000000   \n",
       "medium         count  11229.000000  11229.000000  11229.000000   \n",
       "               mean       0.176151      0.010954      5.813251   \n",
       "               std        0.380966      0.104090      2.654043   \n",
       "               min        0.000000      0.000000      0.000000   \n",
       "               25%        0.000000      0.000000      4.000000   \n",
       "               50%        0.000000      0.000000      5.000000   \n",
       "               75%        0.000000      0.000000      7.000000   \n",
       "               max        1.000000      1.000000     28.000000   \n",
       "\n",
       "                      n_num_keyfeat_score  num_description_words  has_phone  \n",
       "interest_level                                                               \n",
       "high           count          3839.000000            3839.000000        NaN  \n",
       "               mean              0.457671              91.258140        NaN  \n",
       "               std               1.045957              54.509445        NaN  \n",
       "               min               0.000000               1.000000        NaN  \n",
       "               25%               0.000000              53.000000        NaN  \n",
       "               50%               0.000000              84.000000        NaN  \n",
       "               75%               0.000000             119.000000        NaN  \n",
       "               max               6.000000             549.000000        NaN  \n",
       "low            count         34284.000000           34284.000000        NaN  \n",
       "               mean              0.445922              87.525201        NaN  \n",
       "               std               0.960691              60.732700        NaN  \n",
       "               min               0.000000               1.000000        NaN  \n",
       "               25%               0.000000              46.000000        NaN  \n",
       "               50%               0.000000              81.000000        NaN  \n",
       "               75%               0.000000             117.000000        NaN  \n",
       "               max               6.000000             667.000000        NaN  \n",
       "medium         count         11229.000000           11229.000000        NaN  \n",
       "               mean              0.590168              97.733547        NaN  \n",
       "               std               1.118629              56.112246        NaN  \n",
       "               min               0.000000               1.000000        NaN  \n",
       "               25%               0.000000              59.000000        NaN  \n",
       "               50%               0.000000              91.000000        NaN  \n",
       "               75%               1.000000             127.000000        NaN  \n",
       "               max               6.000000             630.000000        NaN  "
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_df.groupby('interest_level').describe().loc[:,pred_logit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "n_log_price           0.214972\n",
       "n_expensive           0.202919\n",
       "price_vs_median_30    0.130221\n",
       "dtype: float64"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Price vars have the highest correl with other features, yet still on average is low\n",
    "# That said, shortlisted predictors have a dual nature with some of them exhibiting low correl and others high\n",
    "# price_vs_median_30 is very local and low correl with the other two price-related predictors.\n",
    "\n",
    "np.mean(corr_mat_high.loc[:,['n_log_price','n_expensive','price_vs_median_30']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance_from_midtown</th>\n",
       "      <th>dist_to_nearest_tube</th>\n",
       "      <th>dist_to_nearest_school</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bathrooms</th>\n",
       "      <td>-0.092381</td>\n",
       "      <td>-0.024394</td>\n",
       "      <td>-0.101638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bedrooms</th>\n",
       "      <td>-0.035261</td>\n",
       "      <td>-0.061103</td>\n",
       "      <td>-0.086560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>building_id</th>\n",
       "      <td>-0.053546</td>\n",
       "      <td>0.020597</td>\n",
       "      <td>-0.058467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>created_day</th>\n",
       "      <td>0.024110</td>\n",
       "      <td>-0.003281</td>\n",
       "      <td>0.025046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>created_month</th>\n",
       "      <td>0.029039</td>\n",
       "      <td>0.009567</td>\n",
       "      <td>0.025056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>created_year</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dist_to_nearest_school</th>\n",
       "      <td>0.955559</td>\n",
       "      <td>0.242775</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dist_to_nearest_tube</th>\n",
       "      <td>0.170353</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.242775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distance_from_midtown</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.170353</td>\n",
       "      <td>0.955559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_phone</th>\n",
       "      <td>-0.239175</td>\n",
       "      <td>-0.002552</td>\n",
       "      <td>-0.220768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latitude</th>\n",
       "      <td>-0.082071</td>\n",
       "      <td>0.159665</td>\n",
       "      <td>0.159323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>listing_id</th>\n",
       "      <td>0.035095</td>\n",
       "      <td>0.008064</td>\n",
       "      <td>0.031508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longitude</th>\n",
       "      <td>0.569175</td>\n",
       "      <td>0.177970</td>\n",
       "      <td>0.671501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>manager_skill</th>\n",
       "      <td>0.169771</td>\n",
       "      <td>0.013968</td>\n",
       "      <td>0.153666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_broadway</th>\n",
       "      <td>0.060273</td>\n",
       "      <td>-0.027632</td>\n",
       "      <td>0.084549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_expensive</th>\n",
       "      <td>-0.208484</td>\n",
       "      <td>-0.086830</td>\n",
       "      <td>-0.236432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_log_price</th>\n",
       "      <td>-0.539977</td>\n",
       "      <td>-0.119072</td>\n",
       "      <td>-0.597045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_no_photo</th>\n",
       "      <td>0.147543</td>\n",
       "      <td>0.007450</td>\n",
       "      <td>0.159123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_num_keyfeat_score</th>\n",
       "      <td>-0.168338</td>\n",
       "      <td>-0.064691</td>\n",
       "      <td>-0.196847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_price_sqrt</th>\n",
       "      <td>-0.458372</td>\n",
       "      <td>-0.110873</td>\n",
       "      <td>-0.509232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_description_words</th>\n",
       "      <td>-0.119946</td>\n",
       "      <td>-0.039571</td>\n",
       "      <td>-0.146618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_photos</th>\n",
       "      <td>0.087334</td>\n",
       "      <td>0.010577</td>\n",
       "      <td>0.061740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>-0.237486</td>\n",
       "      <td>-0.064430</td>\n",
       "      <td>-0.266419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price_vs_median_30</th>\n",
       "      <td>-0.170046</td>\n",
       "      <td>-0.036394</td>\n",
       "      <td>-0.183980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price_vs_median_72</th>\n",
       "      <td>-0.170046</td>\n",
       "      <td>-0.036394</td>\n",
       "      <td>-0.183980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        distance_from_midtown  dist_to_nearest_tube  \\\n",
       "bathrooms                           -0.092381             -0.024394   \n",
       "bedrooms                            -0.035261             -0.061103   \n",
       "building_id                         -0.053546              0.020597   \n",
       "created_day                          0.024110             -0.003281   \n",
       "created_month                        0.029039              0.009567   \n",
       "created_year                              NaN                   NaN   \n",
       "dist_to_nearest_school               0.955559              0.242775   \n",
       "dist_to_nearest_tube                 0.170353              1.000000   \n",
       "distance_from_midtown                1.000000              0.170353   \n",
       "has_phone                           -0.239175             -0.002552   \n",
       "latitude                            -0.082071              0.159665   \n",
       "listing_id                           0.035095              0.008064   \n",
       "longitude                            0.569175              0.177970   \n",
       "manager_skill                        0.169771              0.013968   \n",
       "n_broadway                           0.060273             -0.027632   \n",
       "n_expensive                         -0.208484             -0.086830   \n",
       "n_log_price                         -0.539977             -0.119072   \n",
       "n_no_photo                           0.147543              0.007450   \n",
       "n_num_keyfeat_score                 -0.168338             -0.064691   \n",
       "n_price_sqrt                        -0.458372             -0.110873   \n",
       "num_description_words               -0.119946             -0.039571   \n",
       "num_photos                           0.087334              0.010577   \n",
       "price                               -0.237486             -0.064430   \n",
       "price_vs_median_30                  -0.170046             -0.036394   \n",
       "price_vs_median_72                  -0.170046             -0.036394   \n",
       "\n",
       "                        dist_to_nearest_school  \n",
       "bathrooms                            -0.101638  \n",
       "bedrooms                             -0.086560  \n",
       "building_id                          -0.058467  \n",
       "created_day                           0.025046  \n",
       "created_month                         0.025056  \n",
       "created_year                               NaN  \n",
       "dist_to_nearest_school                1.000000  \n",
       "dist_to_nearest_tube                  0.242775  \n",
       "distance_from_midtown                 0.955559  \n",
       "has_phone                            -0.220768  \n",
       "latitude                              0.159323  \n",
       "listing_id                            0.031508  \n",
       "longitude                             0.671501  \n",
       "manager_skill                         0.153666  \n",
       "n_broadway                            0.084549  \n",
       "n_expensive                          -0.236432  \n",
       "n_log_price                          -0.597045  \n",
       "n_no_photo                            0.159123  \n",
       "n_num_keyfeat_score                  -0.196847  \n",
       "n_price_sqrt                         -0.509232  \n",
       "num_description_words                -0.146618  \n",
       "num_photos                            0.061740  \n",
       "price                                -0.266419  \n",
       "price_vs_median_30                   -0.183980  \n",
       "price_vs_median_72                   -0.183980  "
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_mat_high.loc[:,['distance_from_midtown','dist_to_nearest_tube','dist_to_nearest_school']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_log_price</th>\n",
       "      <th>n_expensive</th>\n",
       "      <th>price_vs_median_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bathrooms</th>\n",
       "      <td>0.438246</td>\n",
       "      <td>0.567730</td>\n",
       "      <td>-0.012696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bedrooms</th>\n",
       "      <td>0.642063</td>\n",
       "      <td>0.507885</td>\n",
       "      <td>0.025381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>building_id</th>\n",
       "      <td>0.060879</td>\n",
       "      <td>0.050691</td>\n",
       "      <td>0.030076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>created_day</th>\n",
       "      <td>-0.027078</td>\n",
       "      <td>-0.020424</td>\n",
       "      <td>-0.021118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>created_month</th>\n",
       "      <td>-0.001680</td>\n",
       "      <td>-0.018517</td>\n",
       "      <td>0.010946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>created_year</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dist_to_nearest_school</th>\n",
       "      <td>-0.597045</td>\n",
       "      <td>-0.236432</td>\n",
       "      <td>-0.183980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dist_to_nearest_tube</th>\n",
       "      <td>-0.119072</td>\n",
       "      <td>-0.086830</td>\n",
       "      <td>-0.036394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distance_from_midtown</th>\n",
       "      <td>-0.539977</td>\n",
       "      <td>-0.208484</td>\n",
       "      <td>-0.170046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_phone</th>\n",
       "      <td>0.219396</td>\n",
       "      <td>0.089825</td>\n",
       "      <td>0.050975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latitude</th>\n",
       "      <td>-0.143268</td>\n",
       "      <td>-0.067000</td>\n",
       "      <td>-0.038271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>listing_id</th>\n",
       "      <td>-0.010239</td>\n",
       "      <td>-0.025612</td>\n",
       "      <td>0.003645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longitude</th>\n",
       "      <td>-0.498750</td>\n",
       "      <td>-0.201178</td>\n",
       "      <td>-0.130683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>manager_skill</th>\n",
       "      <td>-0.071746</td>\n",
       "      <td>-0.004374</td>\n",
       "      <td>-0.037043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_broadway</th>\n",
       "      <td>-0.072354</td>\n",
       "      <td>-0.028075</td>\n",
       "      <td>-0.017914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_expensive</th>\n",
       "      <td>0.649841</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.160617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_log_price</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.649841</td>\n",
       "      <td>0.380090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_no_photo</th>\n",
       "      <td>-0.132242</td>\n",
       "      <td>-0.039776</td>\n",
       "      <td>-0.044189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_num_keyfeat_score</th>\n",
       "      <td>0.312304</td>\n",
       "      <td>0.152169</td>\n",
       "      <td>0.085939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_price_sqrt</th>\n",
       "      <td>0.957952</td>\n",
       "      <td>0.667708</td>\n",
       "      <td>0.598086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_description_words</th>\n",
       "      <td>0.241819</td>\n",
       "      <td>0.122269</td>\n",
       "      <td>0.057045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_photos</th>\n",
       "      <td>0.164724</td>\n",
       "      <td>0.134872</td>\n",
       "      <td>-0.010916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>0.649966</td>\n",
       "      <td>0.449747</td>\n",
       "      <td>0.919734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price_vs_median_30</th>\n",
       "      <td>0.380090</td>\n",
       "      <td>0.160617</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price_vs_median_72</th>\n",
       "      <td>0.380090</td>\n",
       "      <td>0.160617</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        n_log_price  n_expensive  price_vs_median_30\n",
       "bathrooms                  0.438246     0.567730           -0.012696\n",
       "bedrooms                   0.642063     0.507885            0.025381\n",
       "building_id                0.060879     0.050691            0.030076\n",
       "created_day               -0.027078    -0.020424           -0.021118\n",
       "created_month             -0.001680    -0.018517            0.010946\n",
       "created_year                    NaN          NaN                 NaN\n",
       "dist_to_nearest_school    -0.597045    -0.236432           -0.183980\n",
       "dist_to_nearest_tube      -0.119072    -0.086830           -0.036394\n",
       "distance_from_midtown     -0.539977    -0.208484           -0.170046\n",
       "has_phone                  0.219396     0.089825            0.050975\n",
       "latitude                  -0.143268    -0.067000           -0.038271\n",
       "listing_id                -0.010239    -0.025612            0.003645\n",
       "longitude                 -0.498750    -0.201178           -0.130683\n",
       "manager_skill             -0.071746    -0.004374           -0.037043\n",
       "n_broadway                -0.072354    -0.028075           -0.017914\n",
       "n_expensive                0.649841     1.000000            0.160617\n",
       "n_log_price                1.000000     0.649841            0.380090\n",
       "n_no_photo                -0.132242    -0.039776           -0.044189\n",
       "n_num_keyfeat_score        0.312304     0.152169            0.085939\n",
       "n_price_sqrt               0.957952     0.667708            0.598086\n",
       "num_description_words      0.241819     0.122269            0.057045\n",
       "num_photos                 0.164724     0.134872           -0.010916\n",
       "price                      0.649966     0.449747            0.919734\n",
       "price_vs_median_30         0.380090     0.160617            1.000000\n",
       "price_vs_median_72         0.380090     0.160617            1.000000"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_expensive, n_log_price and price_vs_median_30 offer three ways to get price info\n",
    "# price_vs_median_30 is very local and low correl with the former two\n",
    "corr_mat_high.loc[:,['n_log_price','n_expensive','price_vs_median_30']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Feature Correlation %: Average for the 3 classes\n",
      "bathrooms                 16.064993\n",
      "bedrooms                  16.750663\n",
      "building_id                6.300507\n",
      "created_day                4.693413\n",
      "created_month              8.142747\n",
      "created_year                    NaN\n",
      "dist_to_nearest_school     9.158026\n",
      "dist_to_nearest_tube       9.797203\n",
      "distance_from_midtown      8.992846\n",
      "has_phone                  8.287280\n",
      "latitude                  -7.044536\n",
      "listing_id                 9.415611\n",
      "longitude                  8.892199\n",
      "manager_skill              4.451198\n",
      "n_broadway                 3.541817\n",
      "n_expensive               18.647928\n",
      "n_log_price               21.854402\n",
      "n_no_photo                -0.168521\n",
      "n_num_keyfeat_score       11.041983\n",
      "n_price_sqrt              24.100544\n",
      "num_description_words     10.370431\n",
      "num_photos                 8.568384\n",
      "price                     22.040795\n",
      "price_vs_median_30        16.821901\n",
      "price_vs_median_72        16.821901\n",
      "dtype: float64\n",
      "-----------------------------------------------------------------\n",
      "Average Correlation per feature: 10.7309881693\n",
      "Max Correlation per feature: 24.1005440142\n",
      "Min Correlation per feature: -7.04453627107\n"
     ]
    }
   ],
   "source": [
    "# Check correlation among features by interest_level class\n",
    "corr_mat_high = t_df.groupby('interest_level').corr().loc['high']\n",
    "corr_mat_medium = t_df.groupby('interest_level').corr().loc['medium']\n",
    "corr_mat_low = t_df.groupby('interest_level').corr().loc['low']\n",
    "\n",
    "print 'Average Feature Correlation %: Average for the 3 classes'\n",
    "avg= 100*(np.mean(corr_mat_high) + np.mean(corr_mat_medium) + np.mean(corr_mat_low))/3\n",
    "print avg\n",
    "print 65*'-'\n",
    "print 'Average Correlation per feature:',np.mean(avg)\n",
    "print 'Max Correlation per feature:',np.max(avg)\n",
    "print 'Min Correlation per feature:',np.min(avg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average feature correlations differences across 3 classes is summarized below:\n",
      "Standard Average Correl. Dif.\n",
      "bathrooms               -1.878136\n",
      "bedrooms                 0.852161\n",
      "has_phone                2.074892\n",
      "latitude                 4.001767\n",
      "listing_id              -0.111007\n",
      "longitude               -2.988989\n",
      "n_broadway              -0.601892\n",
      "n_expensive              0.353824\n",
      "n_log_price             -0.874444\n",
      "n_no_photo               1.742858\n",
      "n_num_keyfeat_score      0.076327\n",
      "n_price_sqrt             0.814737\n",
      "num_description_words    1.315216\n",
      "price                    6.544959\n",
      "dtype: float64\n",
      "Abs. Value Average Correl. Dif.\n",
      "bathrooms                 4.473327\n",
      "bedrooms                  4.355207\n",
      "has_phone                 2.111560\n",
      "latitude                  4.003076\n",
      "listing_id                0.229446\n",
      "longitude                 2.988989\n",
      "n_broadway                0.774415\n",
      "n_expensive               4.857295\n",
      "n_log_price               5.578755\n",
      "n_no_photo                1.742858\n",
      "n_num_keyfeat_score       2.015810\n",
      "n_price_sqrt              5.867593\n",
      "num_description_words     2.086033\n",
      "price                    15.794593\n",
      "dtype: float64\n",
      "-----------------------------------------------------------------\n",
      "Average feature correlations differences detail per class pairs shown below:\n",
      "-----------------------------------------------------------------\n",
      "Correlation Matrix  - High-Low Correl Differences %\n",
      "-----------------------------------------------------------------\n",
      "bathrooms               -2.817204\n",
      "bedrooms                 1.278242\n",
      "has_phone                3.112339\n",
      "latitude                 6.002651\n",
      "listing_id              -0.166511\n",
      "longitude               -4.483483\n",
      "n_broadway              -0.902838\n",
      "n_expensive              0.530735\n",
      "n_log_price             -1.311666\n",
      "n_no_photo               2.614288\n",
      "n_num_keyfeat_score      0.114491\n",
      "n_price_sqrt             1.222106\n",
      "num_description_words    1.972825\n",
      "price                    9.817438\n",
      "dtype: float64\n",
      "-----------------------------------------------------------------\n",
      "Correlation Matrix  - High-Medium Correl Differences %\n",
      "-----------------------------------------------------------------\n",
      "bathrooms                -6.709990\n",
      "bedrooms                 -5.254569\n",
      "has_phone                -0.055002\n",
      "latitude                  6.004614\n",
      "listing_id                0.177658\n",
      "longitude                -3.454693\n",
      "n_broadway                0.258784\n",
      "n_expensive              -6.755207\n",
      "n_log_price              -8.368132\n",
      "n_no_photo                0.191765\n",
      "n_num_keyfeat_score      -2.909224\n",
      "n_price_sqrt             -7.579284\n",
      "num_description_words    -1.156225\n",
      "price                   -13.874452\n",
      "dtype: float64\n",
      "-----------------------------------------------------------------\n",
      "Correlation Matrix  - Medium-Low Correl Differences %\n",
      "-----------------------------------------------------------------\n",
      "bathrooms                 3.892786\n",
      "bedrooms                  6.532810\n",
      "has_phone                 3.167340\n",
      "latitude                 -0.001963\n",
      "listing_id               -0.344169\n",
      "longitude                -1.028790\n",
      "n_broadway               -1.161622\n",
      "n_expensive               7.285943\n",
      "n_log_price               7.056466\n",
      "n_no_photo                2.422522\n",
      "n_num_keyfeat_score       3.023715\n",
      "n_price_sqrt              8.801390\n",
      "num_description_words     3.129050\n",
      "price                    23.691890\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "h_l_dif = np.mean(corr_mat_high - corr_mat_low)*100\n",
    "h_m_dif = np.mean(corr_mat_high - corr_mat_medium) *100\n",
    "m_l_dif = np.mean(corr_mat_medium - corr_mat_low) *100\n",
    "\n",
    "print 'Average feature correlations differences across 3 classes is summarized below:' \n",
    "print 'Standard Average Correl. Dif.'\n",
    "print (h_l_dif+ h_m_dif + m_l_dif)/3\n",
    "print 'Abs. Value Average Correl. Dif.'\n",
    "print (abs(h_l_dif)+ abs(h_m_dif) + abs(m_l_dif))/3\n",
    "print 65*'-'\n",
    "print 'Average feature correlations differences detail per class pairs shown below:' \n",
    "print 65*'-'\n",
    "print 'Correlation Matrix  - High-Low Correl Differences %'\n",
    "print 65*'-'\n",
    "print h_l_dif\n",
    "print 65*'-'\n",
    "print 'Correlation Matrix  - High-Medium Correl Differences %'\n",
    "print 65*'-'\n",
    "print h_m_dif\n",
    "print 65*'-'\n",
    "print 'Correlation Matrix  - Medium-Low Correl Differences %'\n",
    "print 65*'-'\n",
    "print m_l_dif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discriminant Model Vars:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# predictor list with variables whom relevance has been tested:\n",
    "pred_disc = ['bathrooms', 'bedrooms', 'n_broadway','price_vs_median_30', 'n_log_price','n_expensive',\n",
    "              'n_no_photo','num_photos', 'n_num_keyfeat_score', 'num_description_words', 'has_phone',\n",
    "              'manager_skill','dist_to_nearest_tube']\n",
    "\n",
    "# ['bathrooms', 'bedrooms','longitude', 'latitude', 'n_broadway','price_vs_median_30', 'n_log_price','n_expensive',\n",
    "#               'n_no_photo','num_photos', 'n_num_keyfeat_score', 'num_description_words', 'has_phone','manager_skill']\n",
    "\n",
    "\n",
    "# \n",
    "## separate the predictors and response in the training data set\n",
    "x = np.array(t_df.loc[:, pred_disc])\n",
    "y = np.ravel(t_df.loc[:, 'interest_level'])\n",
    "## separate the predictors and response in the test data set\n",
    "x2 = np.array(ts_df.loc[:, pred_disc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LDA Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Results are similar to Logit model as expected.\n",
    "- Gaussian assumption results in worse performance, yet it seems variance equality asumption is just fine compared to QDA results (see next) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class names; [u'high' u'low' u'medium']\n",
      "Accuracy Training 0.734012805965\n",
      "Multi Class Log_loss: 0.602383462211\n"
     ]
    }
   ],
   "source": [
    "from sklearn import discriminant_analysis\n",
    "LDA = discriminant_analysis.LinearDiscriminantAnalysis()\n",
    "LDA.fit(x, y)\n",
    "\n",
    "print 'Class names;', LDA.classes_\n",
    "print 'Accuracy Training', LDA.score(x,y)\n",
    "print 'Multi Class Log_loss:', metrics.log_loss(y,LDA.predict_proba(x)) # log_loss(x,y) => x= true label format [], x= predicted probs [[]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QDA Model**\n",
    "- QDA Model results are worse than with LDA.\n",
    "- QDA assumption that each class has its own covariance matrix is contrast with our training sample findings (no difference in correl between classes for the majority of features).\n",
    "- For instance, price is one of the most significant features and displays a high correl with other features that varies depending on the class. \n",
    "- Worse yet, bathrooms and bedrooms have higher correlation with price and this effect creates a huge dicotomy in the chosen predictors between those with higher and unstable correlation and those others with low and stable correlation across classes. \n",
    "- In theory, QDA is more flexible than LDA (lower variance), yet our training sample nuances makes QDA accuracy (bias) results very poor compared to LDA.\n",
    "- Last but not least, the gaussian asseumption is also violated as it was mentioned earlier in LDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class names; [u'high' u'low' u'medium']\n",
      "Accuracy Training 0.254883287405\n",
      "Multi Class Log_loss: 3.77288676577\n"
     ]
    }
   ],
   "source": [
    "from sklearn import discriminant_analysis\n",
    "\n",
    "QDA = discriminant_analysis.QuadraticDiscriminantAnalysis()\n",
    "\n",
    "QDA.fit(x, y)\n",
    "\n",
    "print 'Class names;', QDA.classes_\n",
    "print 'Accuracy Training', QDA.score(x,y)\n",
    "print 'Multi Class Log_loss:', metrics.log_loss(y,QDA.predict_proba(x)) # log_loss(x,y) => x= true label format [], x= predicted probs [[]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** GNB Model **\n",
    "- GNB is similar to QDA but adding an extreme assumption: features correlations within each class are nil.\n",
    "- Correl analysis per class suggests that intra-class feature correlations are on average 0.17, yet depending on the feature it can range from 0 to 0.7.\n",
    "- Similar conclusion to QDA: chosen predictors dicotomy in terms of GNB correlation assumption renders an underpeforming model compared LDA.\n",
    "- Last but not least, the gaussian asseumption is also violated as it was mentioned earlier in LDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class names; [u'high' u'low' u'medium']\n",
      "Accuracy Training 0.0802399092235\n",
      "Multi Class Log_loss: 3.58735669436\n"
     ]
    }
   ],
   "source": [
    "from sklearn import naive_bayes\n",
    "gnb = naive_bayes.GaussianNB()\n",
    "\n",
    "gnb.fit(x,y)\n",
    "\n",
    "print 'Class names;', gnb.classes_\n",
    "print 'Accuracy Training', gnb.score(x,y)\n",
    "print 'Multi Class Log_loss:', metrics.log_loss(y,gnb.predict_proba(x)) # log_loss(x,y) => x= true label format [], x= predicted probs [[]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-197-e1358ec031d3>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-197-e1358ec031d3>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    ** BNB Model **\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "** BNB Model **\n",
    "- GNB is similar to QDA but adding an extreme assumption: features correlations within each class are nil.\n",
    "- Correl analysis per class suggests that intra-class feature correlations are on average 0.17, yet depending on the feature it can range from 0 to 0.7.\n",
    "- Similar conclusion to QDA: chosen predictors dicotomy in terms of GNB correlation assumption renders an underpeforming model compared LDA.\n",
    "- Last but not least, the gaussian asseumption is also violated as it was mentioned earlier in LDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## create a instance \n",
    "bnb = naive_bayes.BernoulliNB()\n",
    "## fit model\n",
    "bnb.fit(x, y)\n",
    "print 'Class names;', bnb.classes_\n",
    "print 'Accuracy Training', bnb.score(x,y)\n",
    "print 'Multi Class Log_loss:', metrics.log_loss(y,bnb.predict_proba(x)) # log_loss(x,y) => x= true label format [], x= predicted probs [[]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply models:\n",
    "LDA/QDA => use same predictors as Logit => try to select only numerical ones\n",
    "\n",
    "GNB => same predictors but get rid of bathrooms or bedrooms as they are very correl with prices\n",
    "\n",
    "MNB => try to select only categorical features.\n",
    "\n",
    "BNB => try to select only binary indicators or use binarize wisely."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
